{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b275a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text sentiment\n",
      "0                                i didnt feel humiliated   sadness\n",
      "1      i can go from feeling so hopeless to so damned...   sadness\n",
      "2       im grabbing a minute to post i feel greedy wrong     anger\n",
      "3      i am ever feeling nostalgic about the fireplac...      love\n",
      "4                                   i am feeling grouchy     anger\n",
      "...                                                  ...       ...\n",
      "15995  i just had a very brief time in the beanbag an...   sadness\n",
      "15996  i am now turning and i feel pathetic that i am...   sadness\n",
      "15997                     i feel strong and good overall       joy\n",
      "15998  i feel like this was such a rude comment and i...     anger\n",
      "15999  i know a lot but i feel so stupid because i ca...   sadness\n",
      "\n",
      "[16000 rows x 2 columns]\n",
      "sentiment\n",
      "joy         5362\n",
      "sadness     4666\n",
      "anger       2159\n",
      "fear        1937\n",
      "love        1304\n",
      "surprise     572\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "0    8762\n",
      "1    7238\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaron\\AppData\\Local\\Temp\\ipykernel_21808\\2704362827.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  txt[\"sentiment\"] = txt[\"sentiment\"].replace({\"joy\":1,\"love\":1,\"surprise\":1,\"anger\":0,\"fear\":0,\"sadness\":0})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txt = pd.read_csv(\"sentiments.txt\",names=[\"text\",\"sentiment\"],sep=\";\")\n",
    "print(txt)\n",
    "print(txt[\"sentiment\"].value_counts())\n",
    "\n",
    "txt[\"sentiment\"] = txt[\"sentiment\"].replace({\"joy\":1,\"love\":1,\"surprise\":1,\"anger\":0,\"fear\":0,\"sadness\":0})\n",
    "print(txt[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25033e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(txt[\"text\"],txt[\"sentiment\"],train_size=0.8,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e89bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760151f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def text_transform(data):\n",
    "    corpus = []\n",
    "    for sentence in data:\n",
    "        item = re.sub('[^a-zA-Z]',\" \",sentence) #get rid of anything thats not letters\n",
    "        item = item.lower()\n",
    "        item = item.split(\" \")\n",
    "        lema = []\n",
    "        for word in item:\n",
    "            if word not in stopwords.words(\"english\"):\n",
    "                lema.append(lemmatizer.lemmatize(word))\n",
    "        corpus.append(\" \".join(lema))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f23ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id get class eight dance hour nine get home ten im lucky eat cant eat class dancing full make feel vile sit around digesting etc ish get bed try sleep getting unnaturally early', 'came across picture diy twiggy candle holder im feeling festive creative', 'feel embarrassed talk time feel small moment like favor deserve given attention', 'feel glad starter allowed u interact today', 'need shower child gift feel like caring', 'think folk feeling miserable acknowledge must actually something make world better place', 'feel badly something make really happy', 'feeling almost defeated', 'feeling brave go somewhere afield like walk woodland around farm beach full day activity', 'suspect might also factor making feel rich']\n"
     ]
    }
   ],
   "source": [
    "trans_train = text_transform(X_train)\n",
    "print(trans_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e753edb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800, 88637)\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 25 stored elements and shape (1, 88637)>\n",
      "  Coords\tValues\n",
      "  (0, 24794)\t1\n",
      "  (0, 67483)\t1\n",
      "  (0, 36148)\t1\n",
      "  (0, 54927)\t1\n",
      "  (0, 64139)\t1\n",
      "  (0, 1735)\t1\n",
      "  (0, 23321)\t1\n",
      "  (0, 20825)\t1\n",
      "  (0, 86246)\t1\n",
      "  (0, 63208)\t1\n",
      "  (0, 15747)\t1\n",
      "  (0, 33409)\t1\n",
      "  (0, 20761)\t1\n",
      "  (0, 25816)\t1\n",
      "  (0, 67510)\t1\n",
      "  (0, 36207)\t1\n",
      "  (0, 54928)\t1\n",
      "  (0, 64140)\t1\n",
      "  (0, 1742)\t1\n",
      "  (0, 23333)\t1\n",
      "  (0, 20864)\t1\n",
      "  (0, 86327)\t1\n",
      "  (0, 63214)\t1\n",
      "  (0, 15748)\t1\n",
      "  (0, 33414)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "features = vectorizer.fit_transform(trans_train)\n",
    "trans_test = text_transform(X_test)\n",
    "X_test = vectorizer.transform(trans_test)\n",
    "print(features.shape)\n",
    "print(features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56faaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(features,y_train)\n",
    "predictions = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d85535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1743\n",
      "           1       0.96      0.94      0.95      1457\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.95      0.95      0.95      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "err = classification_report(y_test,predictions)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f089591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text is positive!\n",
      "Your text is negative.\n"
     ]
    }
   ],
   "source": [
    "def Analyser(txt):\n",
    "    txt_trans = text_transform(txt)\n",
    "    txt_num = vectorizer.transform(txt_trans)\n",
    "    pred =  rf_classifier.predict(txt_num)\n",
    "    if pred[0] == 1:\n",
    "        print(\"Your text is positive!\")\n",
    "    else:\n",
    "        print(\"Your text is negative.\")\n",
    "   \n",
    "\n",
    "\n",
    "Analyser([\"I feel very happy about everything\"])\n",
    "Analyser([\"My dog died last week.\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
